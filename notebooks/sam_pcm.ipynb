{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from ultralytics import SAM\n",
    "from ultralytics import RTDETR\n",
    "import copy\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_img = cv2.imread('../asset/example_image.png')\n",
    "depth_img = cv2.imread('../asset/example_depth.png', cv2.IMREAD_ANYDEPTH)\n",
    "Kdepth = np.array([[637.22601318,   0.        , 644.54681396],\n",
    "                    [  0.        , 636.76959229, 363.35079956],\n",
    "                    [  0.        ,   0.        ,   1.        ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Color image: {color_img.dtype, color_img.shape}')\n",
    "print(f'Depth image: {depth_img.dtype, depth_img.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create point cloud\n",
    "pts = cv2.rgbd.depthTo3d(depth_img, Kdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize point cloud\n",
    "verts = pts.reshape((-1,3))\n",
    "idx = ~np.isnan(verts).any(axis=1)\n",
    "verts = verts[idx,:]\n",
    "color = color_img.reshape((-1,3))\n",
    "color = color[idx,:]\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "orig_pcd = pcd\n",
    "pcd.points = o3d.utility.Vector3dVector(verts)\n",
    "pcd.colors = o3d.utility.Vector3dVector(color/255)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_model = RTDETR('rtdetr-x.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cls indices for bottle and cup\n",
    "cls_idxs = [id for id,name in det_model.names.items() if name in ['bottle','cup']]\n",
    "cls_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = det_model(color_img, classes = cls_idxs)\n",
    "det_result = results[0]\n",
    "len(det_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(det_result.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = SAM('mobile_sam.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_result = sam.predict(color_img, bboxes = det_result.boxes.xyxy)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sam_result.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWN_SAMPLE_SIZE = 4e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_pcd = o3d.io.read_point_cloud(\"../asset/bottle_large.pcd\")\n",
    "cnt = np.asarray(ref_pcd.points).shape[0]\n",
    "ref_pcd.colors = o3d.utility.Vector3dVector(np.repeat([[1,0,0]],cnt,axis = 0).astype(np.float32))\n",
    "ref_pcd = ref_pcd.voxel_down_sample(DOWN_SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pose_for_mask(pts,color_img,mask):\n",
    "    objpts = pts[mask,:]\n",
    "    color = color_img[mask,:]\n",
    "\n",
    "    #remove NaNs (e.g. wrong depth pixels)\n",
    "    verts = objpts.reshape((-1,3))\n",
    "    idx = ~np.isnan(verts).any(axis=1)\n",
    "    verts = verts[idx,:]\n",
    "    color = color[idx,:]\n",
    "\n",
    "    # create PCD\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(verts)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(color/255)\n",
    "\n",
    "    # downsample the PCD\n",
    "    pcd_ds = pcd.voxel_down_sample(DOWN_SAMPLE_SIZE)\n",
    "\n",
    "    # default transformation is around the mean of the object, with identity rotation\n",
    "    pts_mean = np.mean(np.asarray(pcd_ds.points),axis=0)\n",
    "    initial_transform = np.block([[np.identity(3), np.asmatrix(pts_mean).T],[0,0,0,1]])\n",
    "\n",
    "    # run pose estimation with different outlier margins\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        ref_pcd, pcd_ds, 1, initial_transform,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=100))\n",
    "\n",
    "\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        ref_pcd, pcd_ds, 0.01, reg_p2p.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=100))\n",
    "    \n",
    "    # create rvec and tvec\n",
    "    tvec = reg_p2p.transformation[0:3,3]\n",
    "    rvec,_ = cv2.Rodrigues(reg_p2p.transformation[0:3,0:3])\n",
    "    rvec = rvec.T[0,:]\n",
    "    return tvec,rvec,reg_p2p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [estimate_pose_for_mask(pts,color_img,mask.numpy()) for mask in sam_result.masks.data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increase figure size for readable text\n",
    "plt.rcParams['figure.figsize'] = [15, 7]\n",
    "\n",
    "seg_debug_img = color_img.copy()\n",
    "\n",
    "for id,(mask,result) in enumerate(zip(sam_result.masks,results)):\n",
    "    mask = mask.data.numpy()[-1,:,:]\n",
    "\n",
    "    blend = result[2].fitness\n",
    "    seg_debug_img[mask,:] = (1 - blend) * seg_debug_img[mask,:] + (blend) * np.array([255,0,0])\n",
    "\n",
    "\n",
    "for id,(mask,result) in enumerate(zip(sam_result.masks,results)):\n",
    "    crd = np.mean(mask.xy,axis=1).astype(np.int32).flatten().tolist()\n",
    "    text = f\"{id} - {result[2].fitness:0.2} - {result[2].inlier_rmse:0.3}\"\n",
    "    cv2.putText(seg_debug_img,org=crd,text=text,fontFace = 0, fontScale = 0.4, color = (0,255,0), thickness = 1)\n",
    "\n",
    "plt.imshow(seg_debug_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FITNESS_LIMIT = 0.5\n",
    "filtered_results = filter(lambda x: x[2].fitness > FITNESS_LIMIT, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ref_point_cloud(transform):\n",
    "    ref_pcd_temp = copy.deepcopy(ref_pcd)\n",
    "    return ref_pcd_temp.transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_all = [generate_ref_point_cloud(reg_res.transformation) for _,_,reg_res in filtered_results]\n",
    "o3d.visualization.draw_geometries([pcd, *pcd_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best by fitness\n",
    "all_fitness = [res[2].fitness for res in results]\n",
    "best_pcd_idx = all_fitness.index(max(all_fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_best = generate_ref_point_cloud(results[best_pcd_idx][2].transformation)\n",
    "o3d.visualization.draw_geometries([pcd, pcd_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
