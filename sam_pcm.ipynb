{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rosbags.rosbag2 import Reader\n",
    "from rosbags.serde import deserialize_cdr\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import itertools\n",
    "import collections\n",
    "from ultralytics import RTDETR\n",
    "from ultralytics import SAM\n",
    "from ultralytics import YOLO\n",
    "import copy\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = '/storage/projects/AIMS5.0/stuff/uc6/data/ros2bag_02'\n",
    "filename = '/storage/projects/AIMS5.0/stuff/uc6/data/rosbag2_2024_04_04-08_57_42' #rosbag2_2024_04_10-12_39_57'\n",
    "#filename = '/ftp/rosbag2_2024_04_04-08_57_42/'\n",
    "with Reader(filename) as reader:\n",
    "    print(reader.start_time/1e9)\n",
    "    print(reader.end_time/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = collections.OrderedDict()\n",
    "with Reader(filename) as reader:\n",
    "    for connection, timestamp, rawdata in itertools.islice(reader.messages(start = 1712221075_910_351_800),50):  # start = 1712752801_000_000_000\n",
    "        try:\n",
    "            b = deserialize_cdr(rawdata, connection.msgtype)\n",
    "            ts = b.header.stamp.sec * 1000000000 + b.header.stamp.nanosec\n",
    "\n",
    "            if ts not in data_all:\n",
    "                data_all[ts] = {}\n",
    "\n",
    "            data_all[ts][connection.topic] = b\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "data = {k: v for k,v in data_all.items() if '/camera/aligned_depth_to_color/image_raw' in v and \n",
    "                                        '/camera/color/image_raw' in v and\n",
    "                                         '/camera/aligned_depth_to_color/camera_info' in v }\n",
    "                \n",
    "for k,v in data.items():\n",
    "    print(k)\n",
    "    for o in v.keys():\n",
    "        print(f'  {o}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_entry = data[list(data.keys())[0]]\n",
    "img_raw = data_entry['/camera/color/image_raw']\n",
    "color_img = np.frombuffer(img_raw.data, dtype = np.uint8).reshape(img_raw.height, img_raw.width,3)\n",
    "depth_raw = data_entry['/camera/aligned_depth_to_color/image_raw']\n",
    "depth_img = np.frombuffer(depth_raw.data, dtype = np.uint16).reshape(depth_raw.height, depth_raw.width)\n",
    "Kdepth = data_entry['/camera/aligned_depth_to_color/camera_info'].k.reshape(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(depth_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create point cloud\n",
    "pts = cv2.rgbd.depthTo3d(depth_img, Kdepth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize point cloud\n",
    "verts = pts.reshape((-1,3))\n",
    "idx = ~np.isnan(verts).any(axis=1)\n",
    "verts = verts[idx,:]\n",
    "color = color_img.reshape((-1,3))\n",
    "color = color[idx,:]\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "orig_pcd = pcd\n",
    "pcd.points = o3d.utility.Vector3dVector(verts)\n",
    "pcd.colors = o3d.utility.Vector3dVector(color/255)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pcd_raw = data_entry['/camera/depth/color/points']\n",
    "pcd_intel = np.frombuffer(pcd_raw.data,dtype=np.float32).reshape(pcd_raw.height,pcd_raw.width,5)\n",
    "\n",
    "# visualize point cloud\n",
    "verts = pcd_intel[:,:,0:3].reshape((-1,3))\n",
    "idx = ~np.isnan(verts).any(axis=1)\n",
    "verts = verts[idx,:]\n",
    "\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(verts)\n",
    "#pcd.colors = o3d.utility.Vector3dVector(color/255)\n",
    "o3d.visualization.draw_geometries([pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_model = RTDETR('rtdetr-x.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cls indices for bottle and cup\n",
    "cls_idxs = [id for id,name in det_model.names.items() if name in ['bottle','cup']]\n",
    "cls_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = det_model(color_img, classes = cls_idxs)\n",
    "det_result = results[0]\n",
    "len(det_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(det_result.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = SAM('mobile_sam.pt')\n",
    "#sam_result = sam.predict(color_img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_result = sam.predict(color_img, bboxes = det_result.boxes.xyxy)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(sam_result.plot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWN_SAMPLE_SIZE = 8e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_pcd = o3d.io.read_point_cloud(\"../bottle_large.pcd\")\n",
    "cnt = np.asarray(ref_pcd.points).shape[0]\n",
    "ref_pcd.colors = o3d.utility.Vector3dVector(np.repeat([[1,0,0]],cnt,axis = 0).astype(np.float32))\n",
    "#ref_pcd.transform(np.matrix(\"1,0,0,0; 0,0,-1,0; 0,1,0,0; 0,0,0,1\"))\n",
    "ref_pcd = ref_pcd.voxel_down_sample(DOWN_SAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pose_for_mask(pts,color_img,mask):\n",
    "    objpts = pts[mask,:]\n",
    "    color = color_img[mask,:]\n",
    "\n",
    "    #remove NaNs\n",
    "    verts = objpts.reshape((-1,3))\n",
    "    idx = ~np.isnan(verts).any(axis=1)\n",
    "    verts = verts[idx,:]\n",
    "    color = color[idx,:]\n",
    "\n",
    "    # create PCD\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(verts)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(color/255)\n",
    "\n",
    "    pcd_ds = pcd.voxel_down_sample(DOWN_SAMPLE_SIZE)\n",
    "\n",
    "    pts_mean = np.mean(np.asarray(pcd_ds.points),axis=0)\n",
    "    initial_transform = np.block([[np.identity(3), np.asmatrix(pts_mean).T],[0,0,0,1]])\n",
    "\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        ref_pcd, pcd_ds, 1, initial_transform,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=100))\n",
    "\n",
    "\n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        ref_pcd, pcd_ds, 0.01, reg_p2p.transformation,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(),\n",
    "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=100))\n",
    "    \n",
    "\n",
    "    tvec = reg_p2p.transformation[0:3,3]\n",
    "    rvec,_ = cv2.Rodrigues(reg_p2p.transformation[0:3,0:3])\n",
    "    rvec = rvec.T[0,:]\n",
    "    return tvec,rvec,reg_p2p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimate_pose_for_mask(pts,color_img,sam_result.masks[1].cpu().data.numpy())\n",
    "\n",
    "results = [estimate_pose_for_mask(pts,color_img,mask.numpy()) for mask in sam_result.masks.data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_debug_img = color_img.copy()\n",
    "\n",
    "for id,(mask,result) in enumerate(zip(sam_result.masks,results)):\n",
    "    mask = mask.data.numpy()[-1,:,:]\n",
    "\n",
    "    blend = result[2].fitness\n",
    "    seg_debug_img[mask,:] = (1 - blend) * seg_debug_img[mask,:] + (blend) * np.array([255,0,0])\n",
    "\n",
    "\n",
    "for id,(mask,result) in enumerate(zip(sam_result.masks,results)):\n",
    "    crd = np.mean(mask.xy,axis=1).astype(np.int32).flatten().tolist()\n",
    "    text = f\"{id} - {result[2].fitness:0.2} - {result[2].inlier_rmse:0.3}\"\n",
    "    cv2.putText(seg_debug_img,org=crd,text=text,fontFace = 0, fontScale = 0.4, color = (0,255,0), thickness = 1)\n",
    "\n",
    "plt.imshow(seg_debug_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ref_point_cloud(transform):\n",
    "    ref_pcd_temp = copy.deepcopy(ref_pcd)\n",
    "    return ref_pcd_temp.transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_all = [generate_ref_point_cloud(reg_res.transformation) for _,_,reg_res in results]\n",
    "o3d.visualization.draw_geometries([pcd, *pcd_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best by fitness\n",
    "all_fitness = [res[2].fitness for res in results]\n",
    "best_pcd_idx = all_fitness.index(max(all_fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_best = generate_ref_point_cloud(results[best_pcd_idx][2].transformation)\n",
    "o3d.visualization.draw_geometries([pcd, pcd_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
